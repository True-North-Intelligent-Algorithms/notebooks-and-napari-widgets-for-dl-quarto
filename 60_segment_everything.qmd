---
title: "Notebooks and Widgets for Deep Learning"
format:
  revealjs:
          theme: default
          slide-number: true
          footer: Northeast Bioimage Analysis Meeting
          transition: "slide"
          highlight-style: arrow
          chalkboard: 
              buttons: false
          controls-layout: bottom-right
  html:
    code-fold: true
jupyter: python3
---

## Segment Everything ?

* Can we segment everything with one generalist model ?
  * maybe someday ?

## What is SAM ?

* SAM stands for Segment Anything Model. 
* Prompt based generalist image segmentation.
  * Prompt is a hint as to what object(s) to segment
  * Prompt can be a point, boundin box, or even a mask (first guess)
* Good at detecting overlapping objects (spots on Ladybugs)
  * multiple prompts -> multiple masks
  * masks may overlap
  * if we want 2D label image need to 'project' 3D collection to 2D

## Viewing and exploring overlapping labels

* this example uses [mobile SAM]((https://github.com/ChaoningZhang/MobileSAM)) and [napari-segment-everything](https://www.napari-hub.org/plugins/napari-segment-everything)

```{python}  
from segment_everything.detect_and_segment import segment_from_stacked_labels
from segment_everything.prompt_generator import YoloDetector
from segment_everything.weights_helper import get_weights_path
from segment_everything.stacked_labels import StackedLabels
from segment_everything.detect_and_segment import segment_from_stacked_labels
import matplotlib.pyplot as plt
from tnia.plotting.plt_helper import random_label_cmap, mask_overlay

conf = 0.3
iou = 0.8
imagesz = 1024
descriptor = "MobileSAM Model"
boxes = True

yolo_detecter = YoloDetector(str(get_weights_path("ObjectAwareModel")), "ObjectAwareModelFromMobileSamV2", device='cuda')

from skimage.io import imread
import os

data_path = r'./data'
parent_path = os.path.join(data_path, 'ladybugs_SAM')
image_name = os.path.join(parent_path, '620818_780868.jpg')

img = imread(image_name)

plt.imshow(img)

```

## Segment bounding boxes
```{python}
#| echo: false
#| include: false 
results = yolo_detecter.get_results(img, conf=conf, iou= iou, imgsz=imagesz, max_det=10000)
bbs=results[0].boxes.xyxy.cpu().numpy()
stacked_labels = StackedLabels.from_yolo_results(bbs, None, img)

import napari
from  napari_segment_everything import segment_everything

viewer = napari.Viewer()
segment_everything_widget=segment_everything.NapariSegmentEverything(viewer)
viewer.window.add_dock_widget(segment_everything_widget)
segment_everything_widget.load_project(stacked_labels.image, stacked_labels.mask_list)
```

```{python}
screenshot = viewer.screenshot(r'./yolo_masks.png', canvas_only=False)
plt.imshow(screenshot)
viewer.close()
```

## SAM with Yolo bbs as prompt

```{python}
#| echo: false
#| include: false 
segmented_stacked_labels = segment_from_stacked_labels(stacked_labels, "MobileSamV2")
segmented_stacked_labels.sort_largest_to_smallest()
labels = segmented_stacked_labels.make_2d_labels(type="min")

viewer = napari.Viewer()
segment_everything_widget=segment_everything.NapariSegmentEverything(viewer)
viewer.window.add_dock_widget(segment_everything_widget)
segment_everything_widget.load_project(segmented_stacked_labels.image, segmented_stacked_labels.mask_list)

```

```{python}
screenshot = viewer.screenshot(r'./SAM_masks.png', canvas_only=False)
plt.imshow(screenshot)
viewer.close()
```

## Rotate to see relationships 

```{=html}
<video id="myVideo" width="640" height="360" autoplay loop muted controls>
  <source src="./napari-segmnet-everything.mp4" type="video/mp4">
  Your browser does not support the video tag.
</video>

## Pan and zoom 

```{=html}
<video id="myVideo" width="640" height="360" autoplay loop muted controls>
  <source src="./napari-segmnet-everything-2.mp4" type="video/mp4">
  Your browser does not support the video tag.
</video>




